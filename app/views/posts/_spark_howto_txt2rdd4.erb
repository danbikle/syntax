<code class='bash'>>>> 
>>> 
>>> spy_rdd.count()
15/01/30 09:52:14 INFO FileInputFormat: Total input paths to process : 1

snip

15/01/30 09:52:17 INFO DAGScheduler: Stage 0 (count at <stdin>:1) finished in 2.191 s
15/01/30 09:52:17 INFO DAGScheduler: Job 0 finished: count at <stdin>:1, took 2.723819 s
5542
>>> 
>>> 


>>> 
>>> spy_rdd.first()
15/01/30 09:54:27 INFO SparkContext: Starting job: runJob at PythonRDD.scala:344
15/01/30 09:54:27 INFO DAGScheduler: Got job 1 (runJob at PythonRDD.scala:344) with 1 output partitions (allowLocal=true)

snip

15/01/30 09:54:27 INFO DAGScheduler: Stage 1 (runJob at PythonRDD.scala:344) finished in 0.072 s
15/01/30 09:54:27 INFO DAGScheduler: Job 1 finished: runJob at PythonRDD.scala:344, took 0.123063 s
u'Date,Open,High,Low,Close,Volume,Adj Close'
>>> 
>>> 
</code>
