<code class='bash'>dan@feb ~ $ 
dan@feb ~ $ 
dan@feb ~ $ cd spark
dan@feb ~/spark $ 
dan@feb ~/spark $ 
dan@feb ~/spark $ ~/spark/bin/pyspark
Python 2.7.8 |Anaconda 2.1.0 (64-bit)| (default, Aug 21 2014, 18:22:21) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
Anaconda is brought to you by Continuum Analytics.
Please check out: http://continuum.io/thanks and https://binstar.org
Spark assembly has been built with Hive, including Datanucleus jars on classpath
Using Spark s default log4j profile: org/apache/spark/log4j-defaults.properties
15/01/31 07:05:15 WARN Utils: Your hostname, feb resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface eth0)
15/01/31 07:05:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
15/01/31 07:05:16 INFO SecurityManager: Changing view acls to: dan
15/01/31 07:05:16 INFO SecurityManager: Changing modify acls to: dan
15/01/31 07:05:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(dan); users with modify permissions: Set(dan)
15/01/31 07:05:17 INFO Slf4jLogger: Slf4jLogger started
15/01/31 07:05:18 INFO Remoting: Starting remoting
15/01/31 07:05:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.2.15:46610]
15/01/31 07:05:18 INFO Utils: Successfully started service 'sparkDriver' on port 46610.
15/01/31 07:05:18 INFO SparkEnv: Registering MapOutputTracker
15/01/31 07:05:18 INFO SparkEnv: Registering BlockManagerMaster
15/01/31 07:05:18 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20150131070518-9ced
15/01/31 07:05:19 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
15/01/31 07:05:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/01/31 07:05:20 INFO HttpFileServer: HTTP File server directory is /tmp/spark-92633c92-2468-4642-9b73-68cc7c7404d4
15/01/31 07:05:20 INFO HttpServer: Starting HTTP Server
15/01/31 07:05:20 INFO Utils: Successfully started service 'HTTP file server' on port 34068.
15/01/31 07:05:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
15/01/31 07:05:20 INFO SparkUI: Started SparkUI at http://10.0.2.15:4040
15/01/31 07:05:21 INFO AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@10.0.2.15:46610/user/HeartbeatReceiver
15/01/31 07:05:21 INFO NettyBlockTransferService: Server created on 35601
15/01/31 07:05:21 INFO BlockManagerMaster: Trying to register BlockManager
15/01/31 07:05:21 INFO BlockManagerMasterActor: Registering block manager localhost:35601 with 265.4 MB RAM, BlockManagerId(<driver>, localhost, 35601)
15/01/31 07:05:21 INFO BlockManagerMaster: Registered BlockManager
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/   _/
   /__ / .__/\_,_/_/ /_/\_\   version 1.2.0
      /_/

Using Python version 2.7.8 (default, Aug 21 2014 18:22:21)
SparkContext available as sc.
>>> 
>>> 
</code>
